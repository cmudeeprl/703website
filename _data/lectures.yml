- date: M 08/31
  lecturer:
  title: >
    <strong>Introduction to Reinforcement Learning and Representation Learning</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture1_introF20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1c22cfaa-c264-4f51-b70f-ac2900e9f81e
  notes:
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch1
    - Smith & Gasser. <a href="http://cogs.indiana.edu/~cogdev/labwork/6_lessons.pdf" target="_blank">The Development of Embodied Cognition - Six Lessons from Babies</a>
    - Dan Wolpert't talk <a href="https://www.ted.com/talks/daniel_wolpert_the_real_reason_for_brains/transcript?language=en#t-1117820" target="blank">The real reason for brains</a>
  logistics:


- date: W 09/02
  lecturer:
  title: >
    <strong>Exploration-exploitation in multi-armed bandits</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture2_banditsF20.pdf
  # slides2: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/lecture_10_2.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=016eddb6-c401-43c8-86a2-ac2c00fb1467
  notes:
  readings:
    - <span style="color:green"><a style="color:green" href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch2 2.1 - 2.7</span>
    - Russo et al. <a href="https://arxiv.org/abs/1707.02038" target="_blank">A Tutorial on Thompson Sampling</a>
  logistics:


- date: F 09/04
  lecturer:
  title: 
  recitation: >
    <strong>CNNs, RNNs, Tensorflow</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_rec1.pdf
  # slides2: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/recitation_2_2.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=4de5da10-964f-4079-9197-ab45012fb789
  notes:
  readings:
    - <a href="https://www.deeplearningbook.org/" target="_blank">G, B & C Textbook</a>, Ch9, Ch10
    - Tensorflow tutorial <a href="https://colab.research.google.com/drive/1IzxXcE__3iUtpS4yOg1lKR2ppNDZ5ix7?usp=sharing" target=  "_blank">notebook</a>
    - OpenAI Gym tutorial <a href="https://colab.research.google.com/drive/1Lt4JcWknxSZjtP18sXyUPExq0CHr-_UB#scrollTo=OR2z_eGUxQr1" target=  "_blank">notebook</a>
    # - <a href="https://www.tensorflow.org/guide/keras" target=  "_blank">The TensorFlow High Level (Keras) API</a>
  logistics:


- date: M 09/07
  lecturer:
  title: >
    <strong> Labor day - No classes </strong>

 
- date: W 09/09
  lecturer:
  title: >
    <strong>Evolutionary methods for policy search</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture3_evolutionarymethods_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=4c421ffb-b408-4f07-b601-ac3101226b08
  notes:
  readings:
    - Nikolaus Hansen. <a href="https://arxiv.org/pdf/1604.00772.pdf" target="_blank">The CMA Evolution Strategy - A Tutorial</a>
    - <span style="color:green">Salimans et al. <a style="color:green" href="https://arxiv.org/abs/1703.03864" target="_blank">Evolution Strategies as a Scalable Alternative to Reinforcement Learning</a></span>
    - Mouret and Clune. <a href="https://arxiv.org/abs/1504.04909" target="_blank">Illuminating search spaces by mapping elites</a>
    - <span style="color:green">Cully et al. <a style="color:green" href="https://arxiv.org/abs/1407.3501" target="_blank">Robots that can adapt like animals</a></span>
    - Wang et al. <a href="https://arxiv.org/abs/1901.01753" target="_blank">Paired Open-Ended Trailblazer (POET)<span>:</span> Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions</a>(Optional)
    # - Optional&#58; Zhang et al. <a href="https://arxiv.org/abs/1712.06564" target="_blank">On the Relationship Between the OpenAI Evolution Strategy and Stochastic Gradient Descent</a>
  logistics:  

  

- date: F 09/11
  lecturer:
  title:
  recitation: >
    <strong>Gaussian Processes</strong>
  slides: https://cmudeeprl.github.io/703website/assets/recitations/s20_lecture3.pdf
  # slides2: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_rec2_openai.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=0f96166f-3c34-44d9-bb96-ac330113c597
  notes:
  readings:
    # - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics: 


# - date: M 09/14
#   lecturer:
#   title: >
#     <strong>Exploration-exploitation in experiment design, Bayesian optimization (contd.)</strong>
#   # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture3.pdf
#   # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=eb36184f-8f73-4880-9751-aab500f4b44e
#   notes:
#   readings:
#   - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch4 Section 2.1-2.8 
#   - <reading class="important">Rasmussen & Williams <a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" target="_blank">Gaussian Processes for Machine Learning</a> Chapter 1,2 </reading>
#   - <reading class="important">Brochu et. al <a href="https://arxiv.org/pdf/1012.2599.pdf" target="_blank">A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning</a> Sections 1, 2.1, 2.2 </reading>
#   logistics:



- date: M 09/14
  lecturer:
  title: >
    <strong>Exploration-exploitation in experiment design, Bayesian optimization with Gaussian Processes</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture4_GPExperimentDesignF20.pdf
  # slides2: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture3.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=f8e17ef5-a2b5-4584-9c5e-ac360125b7f2
  notes:
  readings:
    # - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch4 Section 2.1-2.8 
    - Rasmussen & Williams <a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" target="_blank">Gaussian Processes for Machine Learning</a> Chapter 1, 2.1-2.3
    - Brochu et. al <a href="https://arxiv.org/pdf/1012.2599.pdf" target="blank">A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning</a> Sections 1, 2.1, 2.2
  logistics: <span class="event">HW1 out</span> <br>


- date: W 09/16
  lecturer:
  title: >
    <strong>Imitation learning with behavior cloning</strong>  
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture5_immitationlearning_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=f4c01de5-6241-4e56-a205-ac38011ec8d8
  notes:
  readings:
    - Bagnell. <a href="http://www.ri.cmu.edu/publication_view.html?pub_id=7891" target="_blank">An Invitation to Imitation</a>
    - <span style="color:green">Bojarski et al. <a style="color:green" href="https://arxiv.org/abs/1604.07316" target="_blank">End to End Learning for Self-Driving Cars</a></span>
    - <span style="color:green">Bansal et al. <a style="color:green" href="https://arxiv.org/abs/1812.03079" target="_blank">ChauffeurNet&#58; Learning to Drive by Imitating the Best and Synthesizing the Worst</a></span>
    - <span style="color:green">Florence et al. <a style="color:green" href="https://arxiv.org/pdf/1909.06933.pdf" target="_blank">Self-Supervised Correspondence in Visuomotor Policy Learning</a></span>
    - <span style="color:green">Florence et al.Â <a style="color:green" href="https://arxiv.org/abs/1806.08756" target="_blank">Dense Object Nets<span>:</span> Learning Dense Visual Object Descriptors By and For Robotic Manipulation</a></span>
    # - Mouret and Clune <a href="https://arxiv.org/abs/1504.04909" target="_blank">Illuminating search spaces by mapping elites</a>
    # - Cully et al. <a href="https://arxiv.org/abs/1407.3501" target="_blank">Robots that can adapt like animals</a>
    # - Wang et al. <a href="https://arxiv.org/abs/1901.01753" target="_blank">Paired Open-Ended Trailblazer (POET)&#58; Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions</a>
    # - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics:


- date: F 09/18
  lecturer:
  title:
  recitation: >
    <strong>HW1</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/recitation_2_1.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=7c92e9fb-01c6-45b3-8257-ac3a010d5a85
  notes:
  readings:
    # - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics:



- date: M 09/21
  lecturer:
  title: >
    <strong>Generative adversarial / goal-conditioned imitation learning</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture6_GAILGCILF20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=327788dc-ccb8-4a23-b7f2-ac3d011da09f
  notes:
  readings:
    - Ho et al. <a href="https://cs.stanford.edu/~ermon/papers/imitation_nips2016_main.pdf" target="_blank">Generative Adversarial Imitation Learning</a>
    - Ding et al. <a href="https://arxiv.org/pdf/1906.05838.pdf" target="_blank">Goal-conditioned imitation learning</a>
    - Background Material - 
    - <a href="https://www.deeplearningbook.org/" target="blank"> G, B & C Textbook</a> Ch20
    - Goodfellow et al. <a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" target="_blank">Generative Adversarial Nets</a>
  logistics:


- date: W 09/23
  lecturer:
  title: >
    <strong>What if states are few, we know which state we are in, and the world model is known? Dynamic programming for policy search</strong>
  slides: https://docs.google.com/presentation/d/1gTv2FFHtQvY0fGeKEIM6DPEpX20ZBLpxKGacOUNvmdQ/edit?usp=sharing
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9a67d8ee-d6f0-4f03-b248-ac3f011e0ee3
  notes:
  readings:
    - <span style="color:green"><a style="color:green" href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch3, Ch4</span>
    - <a href="https://distill.pub/2019/paths-perspective-on-value-learning/" target="blank">The Path perspective on Value Learning </a> (blogpost)
  logistics:


- date: F 09/25
  lecturer:
  title:
  recitation: >
    <strong>REC: Behavior Cloning and Quiz 1 Review</strong>
  slides: https://docs.google.com/presentation/d/1s6-Vvq8YEPmv7_sCovW0ityxQe2AZnnOZGF3lfsfD-w/edit?usp=sharing
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=dfa197d6-dd8f-467f-9c0a-ac410131fff1
  notes:
  readings:
    # - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics:


- date: M 09/28
  lecturer:
  title: >
    <strong>Dynamic Programming, Policy Iteration, Value Iteration</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture8_DP_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3852b536-4c5e-4742-95b0-ac44011e5f25
  readings:
    - <span style="color:green"><a style="color:green" href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch3, Ch4</span>
    - <a href="https://distill.pub/2019/paths-perspective-on-value-learning/" target="blank">The Path perspective on Value Learning </a> (blogpost)
  logistics: <span class="deadline">HW1 due 09/28 11:59pm</span>
    



- date: W 09/30
  lecturer:
  title: >
    <strong>Monte Carlo Learning and Temporal Difference Learning</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture9_MCTD_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3993077e-6da6-42a5-af7c-ac46011dbdc5
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch5, Ch6
  logistics:


- date: F 10/02
  lectuerer:
  quiz: >
    <strong> Quiz 1 (online)</strong>  
  logistics: <span class="event">HW2 out</span>


- date: M 10/05
  lecturer:
  title: >
    <strong> What if states are infinite and we do not know or wish to estimate the world model? Deep Q-learning, Deep SARSA</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture10_FA_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=cbcc74fc-a277-441f-9eef-ac4b011d74b3
  notes:
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch 6, Ch 7.1-7.3
    - <span style="color:green">Mnih et al. <a style="color:green" href="https://arxiv.org/pdf/1312.5602.pdf" target="_blank">Playing Atari with Deep Reinforcement Learning</a></span>
    - Hasselt et al. <a href="https://arxiv.org/abs/1509.06461" target="_blank">Deep Reinforcement Learning with Double Q-learning</a>
    - Shaul et al. <a href="https://arxiv.org/abs/1511.05952" target="_blank">Prioritized Experience Replay</a>
    # - Fujimoto et al. <a href="https://arxiv.org/abs/1812.02900" target="_blank">Off-Policy Deep Reinforcement Learning without Exploration</a>
    # - Hester et al. <a href="https://arxiv.org/abs/1704.03732" target="_blank"> Deep Q-learning from Demonstrations</a>
    # - Mandlekar et al. <a href="https://arxiv.org/pdf/1911.05321.pdf" target="_blank">IRIS - Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data</a>
  logistics: 

- date: W 10/07
  lecturer:
  title: >
    <strong>Monte Carlo Tree search / Quiz 1 recap</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture11_MCTS_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=441588a9-b6a7-4ca5-b8bc-ac4d0135d5f3
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch 8.11
    - <span style="color:green">Guo et al. <a style="color:green" href="https://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning" target="_blank"> Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning</a></span>
  logistics: 


- date: F 10/09
  lecturer:
  title:
  recitation: >
    <strong>Policy and Value Iterations</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_rec_pi_vi.pdf
  # slides2: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/recitation_4_2.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b8aa7e36-ebb4-4d1d-9543-ac4f01202c3a
  notes:
  readings:
    # - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics:


- date: M 10/12
  lecturer:
  title: >
    <strong>Monte Carlo Tree search</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture11_MCTS_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=4125c8ea-ca7a-43fb-ae13-ac5201218e69
  notes:
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch 8.11
    - Guo et al. <a href="https://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning" target="_blank"> Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning</a>
  logistics: 


- date: W 10/14
  lecturer:
  title: >
    <strong>Policy gradients, REINFORCE, Actor-Critic methods</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture13_PG_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9e7ae15d-da66-45b6-90ab-ac54012127f4
  notes:
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch13
    - <a href="http://karpathy.github.io/2016/05/31/rl/" target="blank">Deep Reinforcement Learning<span>:</span> Pong from Pixels </a> (blogpost)
    - Mnih et al. <a href="https://arxiv.org/abs/1602.01783" target="_blank">Asynchronous Methods for Deep Reinforcement Learning</a>
  logistics: <span class="event">HW3 out</span> <br> 


- date: F 10/16
  lecturer:
  title: >
    <strong> Community Engagement Day - No classes </strong>
  logistics: <span class="deadline">HW2 due 10/16 11:59pm</span>


- date: M 10/19
  lecturer:
  title: >
    <strong> Actor-Critic methods (cont.), Deterministic PG, Re-parametrized PG</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture14_PG_F20.pdf
  slides2: https://cmudeeprl.github.io/703website/assets/lectures/lecture14_PathwiseDDPG_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5f71ca70-d4ce-4238-82d5-ac59012e655a
  notes:
  readings:
    - <span style="color:green">Mnih et al. <a style="color:green" href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a></span>
    - <span style="color:green">Lillicrap et al. <a style="color:green" href="https://arxiv.org/abs/1509.02971" target="_blank">Continuous control with deep reinforcement learning</a></span>
    # - Silver et al. <a href="https://deepmind.com/research/publications/mastering-game-go-without-human-knowledge" target="_blank">Mastering the Game of Go without Human Knowledge</a>
  logistics:
    

- date: W 10/21
  lecturer:
  title: >
    <strong>Natural PG</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture15_NaturalPolicyGradientsFinalF20F.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9ff18436-65e2-422b-84cd-ac5b0128a4b5
  notes:
  readings:
    - <a href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/#:~:text=Up%20to%20constant%20factor%20of,%E2%88%87%CE%B8L(%CE%B8)." target="blank">Natural Gradient Descent</a> (blogpost)
    - <span style="color:green">Schulman et al. <a style="color:green" href="https://arxiv.org/pdf/1707.06347.pdf" target="_blank">Proximal Policy Optimization Algorithms</a></span>
    # - <span style="color:green">Fujimoto et al. <a style="color:green" href="https://arxiv.org/abs/1812.02900" target="_blank">Off-Policy Deep Reinforcement Learning without Exploration</a></span>
    - <span style="color:green">Schulman et al. <a style="color:green" href="https://arxiv.org/abs/1502.05477" target="_blank">Trust Region Policy Optimization</a></span>
  logistics:


- date: F 10/23
  lecturer:
  title: >
    <strong>Mid Semester Break - No classes</strong>


- date: M 10/26
  lecturer:
  title: >
    <strong>Natural PG (cont.) , off policy RL</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture16_NaturalPolicyGradientsF20.pdf
  slides2: https://cmudeeprl.github.io/703website/assets/lectures/lecture16_offpolicyRL.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3735c17f-3577-4dcd-9add-ac60012946b6
  notes:
  readings:
    - <span style="color:green">Schulman et al. <a style="color:green" href="https://arxiv.org/pdf/1707.06347.pdf" target="_blank">Proximal Policy Optimization Algorithms</a></span>
    - <span style="color:green">Schulman et al. <a style="color:green" href="https://arxiv.org/abs/1502.05477" target="_blank">Trust Region Policy Optimization</a></span>
    - <span style="color:green">Fujimoto et al. <a style="color:green" href="https://arxiv.org/abs/1812.02900" target="_blank">Off-Policy Deep Reinforcement Learning without Exploration</a></span>
    - Doersch <a href="https://arxiv.org/abs/1606.05908" target="_blank">Tutorial on Variational Autoencoders</a>
  logistics:


- date: W 10/28
  lecturer:
  title: >
    <strong>SAC, TD3, soft q learning</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture16_offpolicyRL.pdf
  slides2: https://cmudeeprl.github.io/703website/assets/lectures/lecture17_MaximumEntropyRL.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=caf088d5-87be-4ee9-a535-ac6201277749
  notes:
  readings:
    - <span style="color:green">Haarnoja et al. <a style="color:green" href="https://arxiv.org/abs/1801.01290" target="_blank">Soft Actor-Critic<span>:</span> Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</a></span>
    - <span style="color:green">Haarnoja et al. <a style="color:green" href="https://arxiv.org/abs/1812.05905" target="_blank">Soft Actor-Critic Algorithms and Applications</a></span>
    - <span style="color:green">Fujimoto et al. <a style="color:green" href="https://arxiv.org/abs/1802.09477" target="_blank">Addressing Function Approximation Error in Actor-Critic Methods</a></span>
  logistics:


- date: F 10/30
  lecturer:
  title:
  recitation: >
    <strong>REC </strong>
  slides: https://onedrive.live.com/view.aspx?resid=601D311D0FC404D4!55265&ithint=file%2cpptx&authkey=!ADwylcF15XEfygA
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bf38ff86-ec26-402e-9248-ac64011d49b9
  notes:
  readings:
  logistics: <span class="deadline">HW3 due 10/30 11:59PM</span>


- date: M 11/02
  lecturer: 
  title: >
    <strong>Model-based RL</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture18_modelbasedRL_F20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3af6d108-bd52-414d-9053-ac67012dbbaf
  notes:
  readings:
    - Nagabandi et al. <a href="https://arxiv.org/abs/1708.02596" target="_blank">Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning</a>
    - Chua et al. <a href="https://arxiv.org/abs/1805.12114" target="_blank">Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models</a>
    - Janner et al. <a href="https://arxiv.org/abs/1906.08253" target="_blank">When to Trust Your Model<span>:</span> Model-Based Policy Optimization</a>
    - Kurutach et al. <a href="https://arxiv.org/abs/1802.10592" target="_blank">Model-Ensemble Trust-Region Policy Optimization</a>
  logistics:


- date: W 11/04
  lecturer: 
  title: >
    <strong>Model-based RL (cont.)</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture19_modelbasedRL_F20_2.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=8ae56777-fbfd-43a7-8fa6-ac69012fec16
  notes:
  readings:
    - <span style="color:green">Silver et al. <a style="color:green" href="https://deepmind.com/research/publications/mastering-game-go-without-human-knowledge">Mastering the Game of Go without Human Knowledge</a></span>
    - <span style="color:green">Schrittwieser et al. <a style="color:green" href="https://arxiv.org/abs/1911.08265" target="_blank">Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model</a></span>
    - <span style="color:green">Oh et al. <a style="color:green" href="https://arxiv.org/abs/1507.08750" target="_blank">Action-Conditional Video Prediction using Deep Networks in Atari Games</a></span>
    - <span style="color:green">Kaiser et al. <a style="color:green" href="https://arxiv.org/pdf/1903.00374.pdf" target="_blank">Model Based Reinforcement Learning for Atari</a></span>
  logistics: 


- date: F 11/06
  lecturer:
  quiz: >
    <strong>Quiz 2 (online)</strong>
  logistics:
    <span class="event">HW4 out 11/07</span>


- date: M 11/09
  lecturer:
  title: >
    <strong>Model-based RL (cont.)</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture20_modelbasedRL_F20_3.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=828d3889-a50f-4c49-b9be-ac6e0144cb45
  notes:
  readings:
    -  <span style="color:green">Gonzalez et al. <a style="color:green" href="https://arxiv.org/pdf/2002.09405.pdf" target="_blank">Learning to Simulate Complex Physics with Graph Networks</a></span>
    -  <span style="color:green">Gonzalez et al. <a style="color:green" href="https://arxiv.org/pdf/1806.01242.pdf" target="_blank">Graph Networks as Learnable Physics Engines for Inference and Control</a></span>
    -  <span style="color:green">Agrawal et al. <a style="color:green" href="https://arxiv.org/abs/1606.07419" target="_blank">Learning to Poke by Poking<span>:</span> Experiential Learning of Intuitive Physics</a></span>
    - <span style="color:green">Tutorial - <a style="color:green" href="http://snap.stanford.edu/proj/embeddings-www/" target=  "_blank">Representation Learning on Networks</a></span>
    # - Eysenbach et al. <a href="https://arxiv.org/pdf/1906.05253.pdf" target="_blank">Search on the Replay Buffer- Bridging Planning and Reinforcement Learning</a>
    # - Savinov et al. <a href="https://arxiv.org/abs/1810.02274" target="_blank">Episodic Curiosity through Reachability</a>
    # - Ecoffet et al. <a href="https://arxiv.org/abs/1901.10995" target="_blank">Go-Explore<span>:</span> a New Approach for Hard-Exploration Problems</a>
  logistics: 


- date: W 11/11
  lecturer:
  title: >
    <strong>Curiosity driven exploration</strong>, guest lecture, Deepak Pathak
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture18.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=77adb3fb-2182-4f68-996b-ac70017cee3d
  notes:
  readings:
    - <span style="color:green">Pathak et al. <a style="color:green" href="https://pathak22.github.io/noreward-rl/resources/icml17.pdf" target="_blank">Curiosity-driven Exploration by Self-supervised Prediction</a></span>
    - <span style="color:green">Burda et al. <a style="color:green" href="https://pathak22.github.io/large-scale-curiosity/" target="_blank">Large-Scale Study of Curiosity-Driven Learning</a></span>
    - <span style="color:green">Pathak et al. <a style="color:green" href="https://pathak22.github.io/exploration-by-disagreement/" target="_blank">Self-Supervised Exploration via Disagreement</a></span>
    - <span style="color:green">Sekar et al. <a style="color:green" href="https://arxiv.org/abs/2005.05960" target="_blank">Planning to Explore via Self-Supervised World Models</a></span>
  logistics:


- date: F 11/13
  lecturer: 
  title:
  recitation: >
    <strong>HW4</strong>
  # slides: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=e5781e62-490d-4827-9a03-ac7201347b52
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=e5781e62-490d-4827-9a03-ac7201347b52
  notes:
  readings:
  logistics: 
    

- date: M 11/16
  lecturer:
  title: >
    <strong>Model-based RL (cont.), imitating planners</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture22_modelbasedRL_F20_4.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=0b133213-6efc-4d37-b9e2-ac8100991da1
  notes:
  readings:
    - <span style="color:green">Hafner et al. <a style="color:green" href="https://arxiv.org/pdf/1811.04551.pdf" target="_blank">Learning Latent Dynamics for Planning from Pixels</a></span>
    - <span style="color:green">Hafner et al. <a style="color:green" href="https://arxiv.org/abs/1912.01603" target="_blank">Dream to Control<span>:</span> Learning Behaviors by Latent Imagination</a></span>
    - <span style="color:green">Levine et al. <a style="color:green" href="https://arxiv.org/pdf/1504.00702.pdf" target="_blank">End-to-End Training of Deep Visuomotor Policies</a></span>
    # - Gupta et al. <a href="https://arxiv.org/pdf/1910.11956.pdf" target="_blank">Relay Policy Learning<span>:</span> Solving Long-Horizon Tasks via Imitation and Reinforcement Learning</a>
    # - Nachum et al. <a href="https://arxiv.org/pdf/1805.08296.pdf" target="_blank">Data-Efficient Hierarchical Reinforcement Learning</a>
    # - Nair et al. <a href="https://arxiv.org/abs/1807.04742" target="_blank">Visual Reinforcement Learning with Imagined Goals</a>
  logistics:
    

- date: W 11/18
  lecturer: 
  title:
    <strong>Intelligent Exploration</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture23_deepexplorationF20.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a12cd61e-ed6c-4a12-910c-ac810099aacf
  notes:
  readings:
    - <span style="color:green">Savinov et al. <a style="color:green" href="https://arxiv.org/abs/1810.02274" target="_blank">Episodic Curiosity through Reachability</a></span>
    - <span style="color:green">Ecoffet et al. <a style="color:green" href="https://arxiv.org/abs/1901.10995" target="_blank">Go-Explore<span>:</span> a New Approach for Hard-Exploration Problems</a></span>
    - <span style="color:green">Osband et al. <a style="color:green" href="https://arxiv.org/abs/1602.04621" target="_blank">Deep Exploration via Bootstrapped DQN</a></span>
  logistics: 


- date: F 11/20
  lecturer: 
  title:
  recitation: >
    <strong>HW5</strong>
  slides: https://docs.google.com/presentation/d/1_uGvg55-L6NcthhobOHVKfCsQUMYBKK5Xtzi08-RKh4/edit?usp=sharing
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=14ba06b0-3cc2-44ab-93af-ac83011577dc
  notes:
  readings:
  logistics: 
  

- date: M 11/23
  lecturer:
  title: >
    <strong>Learning and Planning</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture25.pdf
  video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=99bfda7c-951a-4f80-85c1-ac7c0148fe19
  notes: 
  readings:
    - <span style="color:green">Savinov et al. <a style="color:green" href="https://arxiv.org/abs/1803.00653" target="_blank">Semi-parametric Topological Memory for Navigation</a></span>
    - <span style="color:green">Eysenbach et al. <a style="color:green" href="https://arxiv.org/abs/1906.05253" target="_blank">Search on the Replay Buffer<span>:</span> Bridging Planning and Reinforcement Learning</a></span>
    - Emmons et al. <a href="https://arxiv.org/abs/2003.06417" target="_blank">Sparse Graphical Memory for Robust Planning</a>
    - Liu et al. <a href="https://arxiv.org/abs/2002.12336" target="_blank">Hallucinative Topological Memory for Zero-Shot Visual Planning</a>
  logistics:
    <span class="event">HW5 out 11/23</span>
    <span class="deadline">HW4 due 11/23 11:59pm</span> <br>

  # lecturer:
  # title: >
  #   <strong>Hierarchical RL</strong>
  # # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture12.pdf
  # # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ef21a5e2-1b82-4f97-9f83-ab8400e24d5d
  # notes:
  # readings:
  #   - Gupta et al. <a href="https://arxiv.org/pdf/1910.11956.pdf" target="_blank">Relay Policy Learning - Solving Long-Horizon Tasks via Imitation and Reinforcement Learning</a>
  #   - Nachum et al. <a href="https://arxiv.org/pdf/1805.08296.pdf" target="_blank">Data-Efficient Hierarchical Reinforcement Learning</a>
  # logistics: <span class="deadline">HW4 due 11/23 11:59pm</span> <br>
    


- date: W 11/25
  lecturer: 
  title: >
    <strong> Thanksgiving Holiday - No classes </strong>


- date: F 11/27
  lecturer: 
  title: >
    <strong> Thanksgiving Holiday - No classes </strong>


- date: M 11/30
  lecturer:
  title: >
    <strong>Learning from RL and demonstrations</strong>
  slides: https://cmudeeprl.github.io/703website/assets/lectures/lecture25_RDDemovisualimitationF20.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ff2821b7-569d-48e6-94cf-ab10011857b4
  notes:
  readings:
    - Mandlekar et al. <a href="https://arxiv.org/pdf/1911.05321.pdf" target="_blank">IRIS<span>:</span> Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data</a>
    - Salimans et al. <a href="https://arxiv.org/abs/1812.03381" target="_blank">Learning Montezuma's Revenge from a Single Demonstration</a>
    - Peng et al. <a href="https://arxiv.org/abs/1810.03599" target="_blank">SFV<span>:</span> Reinforcement Learning of Physical Skills from Videos</a>
  logistics: 


- date: W 12/02
  lecturer:
  title: >
    <strong>Sim2Real transfer</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture25.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=77ffb580-a960-4806-846d-abaf0131e8e6
  notes: 
  readings:
    - Tobin et al. <a href="https://arxiv.org/abs/1703.06907" target="_blank">Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World</a>
    - Muller et al. <a href="https://arxiv.org/abs/1804.09364" target="_blank">Driving Policy Transfer via Modularity and Abstraction</a>
    - Hwanbo et al. <a href="https://arxiv.org/pdf/1901.08652.pdf" target="_blank">Learning Agile and Dynamic Motor Skills for Legged Robots</a>
    - Hwanbo et al. <a href="https://arxiv.org/pdf/1611.04201.pdf" target="_blank">CAD2RL&#58; Real Single-Image Flight without a Single Real Image</a>
    # - <reading class="important">Bousmalis et al. <a href="https://arxiv.org/abs/1709.07857" target="_blank">Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</a></reading>
  logistics:


- date: F 12/04
  lecturer: 
  title:
  recitation: >
    <strong>REC </strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_rec_hw3.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5f5af510-f977-4634-8820-aaf80108ee41
  notes:
  readings:
  logistics: 


- date: M 12/07
  lecturer:
  title: >
    <strong>Meta-Learning, learning to learn</strong>
  slides:
  slides2: 
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ff2821b7-569d-48e6-94cf-ab10011857b4
  notes:
  readings:
    - Botvinick et al. <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0" target="_blank">Reinforcement Learning, Fast and Slow</a>
    - Duan et al. <a href="https://arxiv.org/abs/1611.02779" target="_blank">RL2&#58; Fast Reinforcement Learning via Slow Reinforcement Learning</a>
    - Duan et al. <a href="https://arxiv.org/pdf/1707.03141.pdf" target="_blank">A Simple Neural Attentive Meta-Learner</a>
    - Finn et al. <a href="https://arxiv.org/abs/1703.03400" target="_blank">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a>
    - Nichol and Schulman <a href="https://d4mucfpksywv.cloudfront.net/research-covers/reptile/reptile_update.pdf" target="_blank">Reptile- a Scalable Metalearning Algorithm</a>
    - Clavera et al. <a href="https://pdfs.semanticscholar.org/39ce/85ad322571b1bdc1d79ee10b9d608960374c.pdf?_ga=2.252655307.391011989.1574704506-1067889836.1572744668" target="_blank">Learning to Adapt&#58; Meta-Learning for Model-Based Control</a>
  logistics: 
    <span class="deadline">HW5 due 12/07 11:59pm</span> <br>


- date: W 12/09
  lecturer:
  title: >
    <strong>RL and generalization: A closer look to state representations for generalization in  model free and model based RL</strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_lecture24.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=d9e3a13e-510d-47b9-80d6-aba8015d49e1
  notes:
  readings:
    - Florence et al. <a href="https://arxiv.org/pdf/1909.06933.pdf" target="_blank">Self-Supervised Correspondence in Visuomotor Policy Learning</a>
    - Tung et al. <a href="https://yjy0625.github.io/publications/v-be_corl2020.pdf" target="_blank"> Visually-Grounded Library of Behaviours for Transfering Manipulation across Objects and Views</a>
    - Zambaldi et al. <a href="https://arxiv.org/pdf/1806.01830.pdf" target="_blank"> Relational Deep Reinforcement Learning</a>
    - Google AI Blog&#58; <a href="https://ai.googleblog.com/2020/06/using-selective-attention-in.html" target="_blank">Using Selective Attention in Reinforcement Learning Agents</a>
    - Ding et al. <a href="https://openreview.net/forum?id=Syx9Q1rYvH" target="_blank"> Mutual Information Maximization for Robust Plannable Representations</a>
  logistics:   

- date: F 12/11
  lecturer: 
  title:
  recitation: >
    <strong>REC </strong>
  # slides: https://cmudeeprl.github.io/Spring202010403website/assets/lectures/s20_rec_hw3.pdf
  # video: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5f5af510-f977-4634-8820-aaf80108ee41
  notes:
  readings:
  logistics: 


- date: M 12/14
  lecturer:
  quiz: >
    <strong>Quiz 3 (online) 1:00 pm - 2:20 pm EST </strong>
  notes:
  readings:
  logistics:
